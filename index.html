<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><title>Where no CPU has gone before</title><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport"><link href="reveal.js/css/reveal.css" rel="stylesheet"><link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
tex2jax: {
  inlineMath: [["\\(", "\\)"]],
  displayMath: [["\\[", "\\]"]],
  ignoreClass: "nostem|nolatexmath"
},
asciimath2jax: {
  delimiters: [["\\$", "\\$"]],
  ignoreClass: "nostem|noasciimath"
},
TeX: { equationNumbers: { autoNumber: "none" } }
});</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.4.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script><link href="reveal.js/lib/css/zenburn.css" rel="stylesheet"><script>var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? "reveal.js/css/print/pdf.css" : "reveal.js/css/print/paper.css";
document.getElementsByTagName( 'head' )[0].appendChild( link );</script><!--[if lt IE 9]><script src="reveal.js/lib/js/html5shiv.js"></script><![endif]--></head><body><div class="reveal"><div class="slides"><section class="title" data-state="title"><h1>Where no CPU has gone before</h1><div class="preamble"><div class="paragraph"><p><a href="http://dcms.tu-dresden.de/project/dcms-materials-4-0-summer-school-2018/">DCMS Materials 4.0 Summer School 2018</a><br></p></div>
<div class="paragraph"><p><a href="mailto:steinbach@scionics.de">Peter Steinbach</a>, September 13, 2018, Dresden, Germany</p></div></div></section>
<section><section id="preface"><h2>Preface</h2></section><section id="my_employer"><h2>My employer</h2><div class="imageblock" style=""><img src="images/scionics_main_logo.png" alt="scionics main logo" width="80%"></div>
<div class="paragraph"><p><a href="https://scionics.de">Scionics Computer Innovation GmbH</a></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>offer scientific consulting</p></li><li><p>data analysis, large data handling, &#8230;&#8203;</p></li></ul></div></aside></section><section id="our_client"><h2>Our client</h2><div class="imageblock" style=""><img src="images/800px-MPI-CBG_building_outside_4pl.jpg" alt="800px MPI CBG building outside 4pl"></div>
<div class="paragraph"><p><a href="https://mpi-cbg.de">Max Planck Institute for Molecular Cell Biology and Genetics</a></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>scientific computing facility</p></li><li><p>my role</p></li></ul></div></aside></section><section id="disclaimer"><h2>Disclaimer</h2><div class="imageblock stretch" style=""><img src="images/bart_simpson_white.png" alt="bart simpson white" height="100%"></div>
<div class="paragraph"><p>These slides are open-source:</p></div>
<div class="paragraph"><p><a href="https://github.com/psteinb/materials4.0-2018">github.com/psteinb/materials4.0-2018</a></p></div></section></section>
<section><section id="deep_learning_in_bits_and_pieces"><h2>Deep Learning in bits and pieces</h2><div class="imageblock" style=""><img src="images/Typical_cnn.png" alt="Typical cnn"></div></section><section id="heavy_lifting_inside_cnns"><h2>Heavy-Lifting inside CNNs</h2><table class="tableblock frame-none grid-none" style="width:100%"><colgroup><col style="width:50%"><col style="width:50%"></colgroup><tbody><tr><td class="tableblock halign-center valign-top"><div><div class="paragraph"><p><span class="image"><img src="images/3D_Convolution_Animation.gif" alt="3D Convolution Animation" width="100%"></span></p></div></div></td><td class="tableblock halign-center valign-top"><div><div class="paragraph"><p><span class="image"><img src="images/Matrix_multiplication_diagram_2.png" alt="Matrix multiplication diagram 2" width="100%"></span></p></div></div></td></tr><tr><td class="tableblock halign-center valign-top"><p class="tableblock"><strong>Convolutions</strong></p></td><td class="tableblock halign-center valign-top"><p class="tableblock"><strong>Matrix Operations</strong></p></td></tr></table></section><section id="a_closer_look"><h2>A closer look</h2><div class="ulist"><ul><li><p>Convolutions<br>
\(y_i = \sum_{n = 0}^{N_k} x_{i+/-n}*k_{i+/-n} \)</p></li><li><p>Matrix Operations<br>
\(AB=Y, y_{ij} = \sum_{k} a_{ik} * b_{kj} \)</p></li><li><p>Common?<br>
<strong>Dot Product Structure!</strong></p></li></ul></div>
<aside class="notes"><div class="ulist"><ul><li><p>thousands of dot-products</p></li><li><p>one HD frame with 3x3 kernel:
 2.067.604 independent pixels
35.149.268 flops
37.216.872 loads
 2.067.604 stores</p></li></ul></div></aside></section><section id="where_do_cpus_come_from"><h2>Where do CPUs come from ?</h2><div class="imageblock" style=""><img src="images/wing-commander.jpg" alt="wing commander" width="100%"></div>
<div class="paragraph"><p>Low Latency Matters Most</p></div>
<aside class="notes"><div class="ulist"><ul><li><p>PC users don&#8217;t want to wait!</p></li></ul></div></aside></section><section id="gpus_for_deep_learning_12"><h2>GPUs for Deep Learning 1/2</h2><div class="imageblock" style=""><img src="images/gpu_cpu_dichotomy.svg" alt="gpu cpu dichotomy" width="100%"></div>
<aside class="notes"><div class="ulist"><ul><li><p>GPU: smallest unit of concurrency 32 (&gt;3000 cores)</p></li><li><p>CPU: smallest unit of concurrency 1 (10-20 cores)</p></li></ul></div></aside></section><section id="gpus_for_deep_learning_22"><h2>GPUs for Deep Learning 2/2</h2><div class="imageblock" style=""><img src="images/high_throughput_smx.svg" alt="high throughput smx" width="100%"></div>
<div class="paragraph"><p>Latency Hiding</p></div>
<aside class="notes"><div class="ulist"><ul><li><p>GPU: hides latency of memory access (larger bandwidth)</p></li><li><p>CPU: can hide latency to some degree only</p></li></ul></div></aside></section><section id="the_rest_is_history"><h2>The rest is <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">history</a></h2><div class="imageblock" style=""><img src="images/image_classification_006_x600.png" alt="image classification 006 x600" height="100%"></div>
<aside class="notes"><div class="ulist"><ul><li><p>2012 first deep learning net by Alex Krizhevsky et al</p></li></ul></div></aside></section><section id="consequences_on_the_market"><h2>Consequences on the market</h2><div class="imageblock" style=""><img src="images/nvidia_stock.png" alt="nvidia stock"></div>
<div class="paragraph"><p>Nvidia&#8217;s stock pricing in the last years</p></div></section></section>
<section><section id="benchmarks"><h2>Benchmarks</h2><div class="imageblock" style=""><img src="images/directions.png" alt="directions"></div><aside class="notes"><div class="ulist"><ul><li><p>beginners typically don&#8217;t know where to go</p></li><li><p>which framework?</p></li><li><p>web is full of good advice</p></li></ul></div></aside></section><section id="benchmarks_what_for"><h2>Benchmarks &#8230;&#8203; What for?</h2><div class="ulist"><ul><li><p><strong>Executive</strong> to decide what to buy new hardware</p></li><li><p><strong>Developer</strong> to compare framework performance</p></li><li><p><strong>User</strong> wanting to e.g. classify images (fast/slow?)</p></li></ul></div>
<aside class="notes"><div class="ulist"><ul><li><p>who are they for?</p></li></ul></div></aside></section><section id="fair_benchmarks"><h2>fair benchmarks</h2><div class="ulist"><ul><li><p>(deep learning) applications try to solve a problem</p></li><li><p>model written in a particular software framework</p></li><li><p>running on particular hardware for training and/or inference</p></li></ul></div>
<div class="admonitionblock tip"><table><tr><td class="icon"><i class="fa fa-lightbulb-o" title="Tip"></i></td><td class="content">Fix at least 2 of 3 from above!</td></tr></table></div></section><section id="dawnbench"><h2><a href="https://dawn.cs.stanford.edu/benchmark/">DawnBench</a></h2><div class="ulist"><ul><li><p>open-source and community driven</p></li><li><p>key requirement: reach fixed accuracy for training for fixed dataset</p></li></ul></div>
<div class="admonitionblock warning"><table><tr><td class="icon"><i class="fa fa-warning" title="Warning"></i></td><td class="content">data from 1 run only</td></tr></table></div>
<div class="admonitionblock warning"><table><tr><td class="icon"><i class="fa fa-warning" title="Warning"></i></td><td class="content">submitter can choose model implementation</td></tr></table></div>
<div class="admonitionblock warning"><table><tr><td class="icon"><i class="fa fa-warning" title="Warning"></i></td><td class="content">data inconsistent (K80 cloud-only, P100 bare-only)</td></tr></table></div></section><section id="mlperf"><h2><a href="https://mlperf.org/">MLperf</a></h2><div class="ulist"><ul><li><p>open-source and community driven</p></li><li><p>industry support (AMD, Google, Intel, &#8230;&#8203;)</p></li><li><p>goal: SPEC benchmark for Deep Learning</p></li></ul></div>
<div class="admonitionblock warning"><table><tr><td class="icon"><i class="fa fa-warning" title="Warning"></i></td><td class="content">data = best of 5 runs</td></tr></table></div></section><section id="deeprace"><h2><a href="https://github.com/psteinb/deeprace">deeprace</a></h2><div class="ulist"><ul><li><p>usable benchmark with clear <a href="https://semver.org">semver</a> support</p></li><li><p>model code is fixed</p></li><li><p><strong>ResNet</strong> with Keras+TensorFlow or just TensorFlow (code adopted from official repos)</p></li><li><p>single and multi-gpu training (distributed planned)</p></li><li><p>data will be open-sourced once I find a sponsor</p></li></ul></div></section></section>
<section><section id="deeprace_results"><h2>Deeprace Results</h2></section><section id="hardware"><h2>Hardware</h2><div class="ulist"><ul><li><p><strong>local cluster</strong>: <a href="https://doc.zih.tu-dresden.de/hpc-wiki/bin/view/Compendium/SystemTaurus">Taurus</a> at Technical University Dresden</p><div class="ulist"><ul><li><p>single GPU node:</p><div class="ulist"><ul><li><p>Intel Xeon E5-2680 v3 12c</p></li><li><p>64GB RAM</p></li><li><p>4x Nvidia Tesla K80 GPU</p></li></ul></div></li></ul></div></li><li><p>local servers (Nvidia Titan Xp, Nvidia Tesla P100)</p></li></ul></div></section><section id="using_resnet_on_cifar10"><h2>Using ResNet on CIFAR10</h2><div class="imageblock" style=""><img src="images/deeprace-full-single.svg" alt="deeprace full single"></div>
<aside class="notes"><div class="ulist"><ul><li><p>Resnet32v1 (and Resnet56v1) as sample models on CIFAR10 dataset</p></li><li><p>time-per-epoch higher for smaller batches (more host-device transfers, backprop more often)</p></li></ul></div></aside></section><section id="containers"><h2>Containers!</h2><div class="imageblock" style=""><img src="images/deeprace-full-vs-singularity.png" alt="deeprace full vs singularity" width="100%"></div>
<div class="paragraph"><p><a href="https://www.sylabs.io/docs/">singularity</a> container = <a href="https://keras.io">Keras 2.1.5</a> + <a href="https://tensorflow.org">TensorFlow 1.3.0</a></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>for setup and reproducibility</p></li><li><p>for the rest, use tf 1.7</p></li></ul></div></aside></section><section id="short_runs_only"><h2>Short runs only</h2><div class="imageblock" style=""><img src="images/deeprace-short-runtimes.png" alt="deeprace short runtimes"></div>
<aside class="notes"><div class="ulist"><ul><li><p>as time per epoch is "flat" &#8594; limit to <code>n=15</code> epochs</p></li><li><p>multiple runs per measurements</p></li></ul></div></aside></section><section id="single_gpu_training"><h2>single-GPU training</h2><div class="imageblock" style=""><img src="images/deeprace-short-hw.png" alt="deeprace short hw"></div>
<aside class="notes"><div class="ulist"><ul><li><p>architecture difference Pascal (2016) and Kepler (2013/2014)</p></li><li><p>note: gaming GPUs</p></li></ul></div></aside></section><section id="cloud"><h2>cloud?</h2><div class="imageblock" style=""><img src="images/deeprace-short-runtimes-vs-cloud.svg" alt="deeprace short runtimes vs cloud"></div>
<div class="paragraph"><p>GCE, single K80 instance, 1vCPU, 6GB RAM, 10GB disk</p></div>
<aside class="notes"><div class="ulist"><ul><li><p>keras:2.1.5,tensorflow:1.7.0</p></li></ul></div></aside></section><section id="framework_differences"><h2>framework differences?</h2><div class="imageblock" style=""><img src="images/deeprace-frameworks.svg" alt="deeprace frameworks"></div>
<aside class="notes"><div class="ulist"><ul><li><p>Titan Xp</p></li></ul></div></aside></section><section id="multi_gpu_training"><h2>multi-GPU training</h2><div class="imageblock" style=""><img src="images/deeprace-short-multi-gpu-compared.png" alt="deeprace short multi gpu compared"></div>
<aside class="notes"><div class="ulist"><ul><li><p>keras:2.1.5,tensorflow:1.7.0</p></li><li><p>batch based parallelisation typically with gradient averaging (only possible with tensorflow 1.5+)</p></li><li><p>no linear scaling is a <a href="https://medium.com/rossum/towards-efficient-multi-gpu-training-in-keras-with-tensorflow-8a0091074fb2">known problem</a></p></li><li><p>numa at play for 2GPU use case</p></li><li><p>still a lot TODOs</p></li></ul></div></aside></section></section>
<section id="summary"><h2>Summary</h2><div class="ulist"><ul><li><p>deep learning requires a lot of parallel compute power</p></li><li><p>GPUs et al are indispensible tools</p></li><li><p>hardware/framework landscape diverse</p></li><li><p>solid benchmarks save time &amp; money</p></li></ul></div></section>
<section id="where_no_hardware_can_go"><h2>Where No Hardware can go</h2><div class="paragraph"><div class="title"><a href="https://arxiv.org/pdf/1803.09820.pdf">Super Convergence, arxiv:1803.09820</a></div><p><span class="image"><img src="images/super-convergence.png" alt="super convergence"></span></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>heuristic to speed up training</p></li><li><p>loss function landscape "known"</p></li><li><p>Cyclical learning rates: specify min. and max. learning rate boundaries</p></li><li><p>Specify number of cycle iterations</p></li><li><p>In each cycle increase learning rate linearly from  min to max and then back down</p></li><li><p>Do a few cycles</p></li><li><p>bottom line: better algorithms always win!</p></li></ul></div></aside></section></div></div><script src="reveal.js/lib/js/head.min.js"></script><script src="reveal.js/js/reveal.js"></script><script>// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display controls in the bottom right corner
  controls: true,
  // Display a presentation progress bar
  progress: true,
  // Set a per-slide timing for speaker notes, null means none
  defaultTiming: null,
  // Display the page number of the current slide
  slideNumber: false,
  // Push each slide change to the browser history
  history: false,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Randomizes the order of slides each time the presentation loads
  shuffle: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Flags if we should show a help overlay when the questionmark
  // key is pressed
  help: true,
  // Flags if speaker notes should be visible to all viewers
  showNotes: false,
  // Global override for autolaying embedded media (video/audio/iframe)
  // - null: Media will only autoplay if data-autoplay is present
  // - true: All media will autoplay, regardless of individual setting
  // - false: No media will autoplay, regardless of individual setting
  autoPlayMedia: null,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Enable slide navigation via mouse wheel
  mouseWheel: false,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  previewLinks: false,
  // Theme (e.g., beige, black, league, night, serif, simple, sky, solarized, white)
  // NOTE setting the theme in the config no longer works in reveal.js 3.x
  //theme: Reveal.getQueryHash().theme || 'black',
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: Reveal.getQueryHash().transition || 'slide',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.5,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
      { src: 'reveal.js/plugin/notes/notes.js', async: true }
  ]
});</script></body></html>